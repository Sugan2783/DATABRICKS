{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a30d11f1-0e3d-4c44-bccd-db13afd7e2cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Databricks notebook source\n",
    "import pandas as pd\n",
    "\n",
    "df_claims = ['claim_id', 'member_id', 'date_of_service', 'amount_paid', 'cpt_code', 'provider_id', 'claim_status']\n",
    "df_icd_ref = ['cpt_code', 'cpt_description']\n",
    "df_providers = ['provider_id', 'provider_name', 'provider_address', 'provider_city', 'provider_state', 'provider_zip']\n",
    "\n",
    "def validate_claims(self,df_claims, df_icd_ref, df_providers):\n",
    "    errors = []\n",
    "\n",
    "    # 1. Schema check\n",
    "    expected_cols = ['claim_id', 'member_id', 'date_of_service', 'amount_paid', 'cpt_code', 'provider_id', 'claim_status']\n",
    "    missing_cols = set(expected_cols) - set(df_claims.columns)\n",
    "    if missing_cols:\n",
    "        errors.append(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "    # 2. Null checks\n",
    "    if df_claims['member_id'].isnull().any():\n",
    "        errors.append(\"Nulls found in member_id\")\n",
    "    if df_claims['date_of_service'].isnull().any():\n",
    "        errors.append(\"Nulls found in date_of_service\")\n",
    "\n",
    "    # 3. Amount range check\n",
    "    if (df_claims['amount_paid'] <= 0).any():\n",
    "        errors.append(\"Amount paid <= 0 found\")\n",
    "\n",
    "    # 4. Code validation (ICD codes)\n",
    "    invalid_icd = df_claims.loc[~df_claims['cpt_code'].isin(df_icd_ref['cpt_code'])]\n",
    "    if not invalid_icd.empty:\n",
    "        errors.append(f\"Invalid CPT codes found: {invalid_icd['cpt_code'].unique()}\")\n",
    "\n",
    "    # 5. Referential integrity (provider IDs)\n",
    "    invalid_providers = df_claims.loc[~df_claims['provider_id'].isin(df_providers['provider_id'])]\n",
    "    if not invalid_providers.empty:\n",
    "        errors.append(f\"Invalid provider IDs found: {invalid_providers['provider_id'].unique()}\")\n",
    "\n",
    "    # 6. Date consistency\n",
    "    invalid_dates = df_claims.loc[df_claims['date_of_service'] > pd.Timestamp.today()]\n",
    "    if not invalid_dates.empty:\n",
    "        errors.append(\"Date of service is in the future\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "# Example usage\n",
    "# df_claims, df_icd_ref, df_providers loaded from data sources\n",
    "\n",
    "validation_errors = validate_claims(df_claims, df_icd_ref, df_providers)\n",
    "if validation_errors:\n",
    "    print(\"Validation Errors Found:\")\n",
    "    for e in validation_errors:\n",
    "        print(\"-\", e)\n",
    "else:\n",
    "    print(\"All validations passed.\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "\n",
    "df_claims = pd.read_csv('claims')\n",
    "df_icd_ref = pd.read_csv('icd_reference')\n",
    "df_providers = pd.read_csv('providers')\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df_claims = pd.read_excel('claims.xlsx', sheet_name='Claims')\n",
    "df_icd_ref = pd.read_excel('codes.xlsx', sheet_name='ICD')\n",
    "df_providers = pd.read_excel('providers.xlsx')\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df_claims = spark.createDataFrame(data=[], schema=['claim_id', 'member_id', 'date_of_service', 'amount_paid', 'cpt_code', 'provider_id', 'claim_status'])\n",
    "df_icd_ref = spark.createDataFrame (data=[], schema=['cpt_code', 'cpt_description'])\n",
    "df_providers = spark.createDataFrame(data=[], schema=['provider_id', 'provider_name', 'provider_address', 'provider_city', 'provider_state', 'provider_zip'])\n",
    "\n",
    "df_claims.write.mode('overwrite').saveAsTable('claims')\n",
    "df_icd_ref.write.mode('overwrite').saveAsTable('icd_ref')\n",
    "df_providers.write.mode('overwrite').saveAsTable('providers')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType\n",
    "\n",
    "# Define schema for df_claims\n",
    "schema_claims = StructType([\n",
    "    StructField('claim_id', StringType(), True),\n",
    "    StructField('member_id', StringType(), True),\n",
    "    StructField('date_of_service', DateType(), True),\n",
    "    StructField('amount_paid', FloatType(), True),\n",
    "    StructField('cpt_code', StringType(), True),\n",
    "    StructField('provider_id', StringType(), True),\n",
    "    StructField('claim_status', StringType(), True)\n",
    "])\n",
    "\n",
    "# Define schema for df_icd_ref\n",
    "schema_icd_ref = StructType([\n",
    "    StructField('cpt_code', StringType(), True),\n",
    "    StructField('cpt_description', StringType(), True)\n",
    "])\n",
    "\n",
    "# Define schema for df_providers\n",
    "schema_providers = StructType([\n",
    "    StructField('provider_id', StringType(), True),\n",
    "    StructField('provider_name', StringType(), True),\n",
    "    StructField('provider_address', StringType(), True),\n",
    "    StructField('provider_city', StringType(), True),\n",
    "    StructField('provider_state', StringType(), True),\n",
    "    StructField('provider_zip', StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrames with defined schemas\n",
    "df_claims = spark.createDataFrame(data=[], schema=schema_claims)\n",
    "df_icd_ref = spark.createDataFrame(data=[], schema=schema_icd_ref)\n",
    "df_providers = spark.createDataFrame(data=[], schema=schema_providers)\n",
    "\n",
    "# Write DataFrames to tables\n",
    "df_claims.write.mode('overwrite').saveAsTable('claims')\n",
    "df_icd_ref.write.mode('overwrite').saveAsTable('icd_ref')\n",
    "df_providers.write.mode('overwrite').saveAsTable('providers')\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrames from the lists\n",
    "df_claims = pd.DataFrame(columns=['claim_id', 'member_id', 'date_of_service', 'amount_paid', 'cpt_code', 'provider_id', 'claim_status'])\n",
    "df_icd_ref = pd.DataFrame(columns=['cpt_code', 'cpt_description'])\n",
    "df_providers = pd.DataFrame(columns=['provider_id', 'provider_name', 'provider_address', 'provider_city', 'provider_state', 'provider_zip'])\n",
    "\n",
    "def validate_claims(df_claims, df_icd_ref, df_providers):\n",
    "    errors = []\n",
    "\n",
    "    # 1. Schema check\n",
    "    expected_cols = ['claim_id', 'member_id', 'date_of_service', 'amount_paid', 'cpt_code', 'provider_id', 'claim_status']\n",
    "    missing_cols = set(expected_cols) - set(df_claims.columns)\n",
    "    if missing_cols:\n",
    "        errors.append(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "    # 2. Null checks\n",
    "    if df_claims['member_id'].isnull().any():\n",
    "        errors.append(\"Nulls found in member_id\")\n",
    "    if df_claims['date_of_service'].isnull().any():\n",
    "        errors.append(\"Nulls found in date_of_service\")\n",
    "\n",
    "    # 3. Amount range check\n",
    "    if (df_claims['amount_paid'] <= 0).any():\n",
    "        errors.append(\"Amount paid <= 0 found\")\n",
    "\n",
    "    # 4. Code validation (ICD codes)\n",
    "    invalid_icd = df_claims.loc[~df_claims['cpt_code'].isin(df_icd_ref['cpt_code'])]\n",
    "    if not invalid_icd.empty:\n",
    "        errors.append(f\"Invalid CPT codes found: {invalid_icd['cpt_code'].unique()}\")\n",
    "\n",
    "    # 5. Referential integrity (provider IDs)\n",
    "    invalid_providers = df_claims.loc[~df_claims['provider_id'].isin(df_providers['provider_id'])]\n",
    "    if not invalid_providers.empty:\n",
    "        errors.append(f\"Invalid provider IDs found: {invalid_providers['provider_id'].unique()}\")\n",
    "\n",
    "    # 6. Date consistency\n",
    "    invalid_dates = df_claims.loc[df_claims['date_of_service'] > pd.Timestamp.today()]\n",
    "    if not invalid_dates.empty:\n",
    "        errors.append(\"Date of service is in the future\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "# Example usage\n",
    "# df_claims, df_icd_ref, df_providers loaded from data sources\n",
    "\n",
    "validation_errors = validate_claims(df_claims, df_icd_ref, df_providers)\n",
    "if validation_errors:\n",
    "    print(\"Validation Errors Found:\")\n",
    "    for e in validation_errors:\n",
    "        print(\"-\", e)\n",
    "else:\n",
    "    print(\"All validations passed.\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrames from the lists\n",
    "df_claims = pd.DataFrame(columns=['claim_id', 'member_id', 'date_of_service', 'amount_paid', 'cpt_code', 'provider_id', 'claim_status'])\n",
    "df_icd_ref = pd.DataFrame(columns=['cpt_code', 'cpt_description'])\n",
    "df_providers = pd.DataFrame(columns=['provider_id', 'provider_name', 'provider_address', 'provider_city', 'provider_state', 'provider_zip'])\n",
    "\n",
    "def validate_claims(df_claims, df_icd_ref, df_providers):\n",
    "    errors = []\n",
    "\n",
    "    # 1. Schema check\n",
    "    expected_cols = ['claim_id', 'member_id', 'date_of_service', 'amount_paid', 'cpt_code', 'provider_id', 'claim_status']\n",
    "    missing_cols = set(expected_cols) - set(df_claims.columns)\n",
    "    if missing_cols:\n",
    "        errors.append(f\"Missing columns: {missing_cols}\")\n",
    "\n",
    "    # 2. Null checks\n",
    "    if df_claims['member_id'].isnull().any():\n",
    "        errors.append(\"Nulls found in member_id\")\n",
    "    if df_claims['date_of_service'].isnull().any():\n",
    "        errors.append(\"Nulls found in date_of_service\")\n",
    "\n",
    "    # 3. Amount range check\n",
    "    if (df_claims['amount_paid'] <= 0).any():\n",
    "        errors.append(\"Amount paid <= 0 found\")\n",
    "\n",
    "    # 4. Code validation (ICD codes)\n",
    "    invalid_icd = df_claims.loc[~df_claims['cpt_code'].isin(df_icd_ref['cpt_code'])]\n",
    "    if not invalid_icd.empty:\n",
    "        errors.append(f\"Invalid CPT codes found: {invalid_icd['cpt_code'].unique()}\")\n",
    "\n",
    "    # 5. Referential integrity (provider IDs)\n",
    "    invalid_providers = df_claims.loc[~df_claims['provider_id'].isin(df_providers['provider_id'])]\n",
    "    if not invalid_providers.empty:\n",
    "        errors.append(f\"Invalid provider IDs found: {invalid_providers['provider_id'].unique()}\")\n",
    "\n",
    "    # 6. Date consistency\n",
    "    invalid_dates = df_claims.loc[df_claims['date_of_service'] > pd.Timestamp.today()]\n",
    "    if not invalid_dates.empty:\n",
    "        errors.append(\"Date of service is in the future\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "# Example usage\n",
    "# df_claims, df_icd_ref, df_providers loaded from data sources\n",
    "\n",
    "validation_errors = validate_claims(df_claims, df_icd_ref, df_providers)\n",
    "if validation_errors:\n",
    "    print(\"Validation Errors Found:\")\n",
    "    for e in validation_errors:\n",
    "        print(\"-\", e)\n",
    "else:\n",
    "    print(\"All validations passed.\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df = pd.DataFrame({'code': ['A', 'B', 'C', 'D']})\n",
    "valid_codes = ['A', 'B']\n",
    "\n",
    "# Shows which codes are valid\n",
    "print(df['code'].isin(valid_codes))\n",
    "# Output: [True, True, False, False]\n",
    "\n",
    "# Use ~ to get the invalid ones\n",
    "print(~df['code'].isin(valid_codes))\n",
    "# Output: [False, False, True, True]\n",
    "\n",
    "# Filter for invalid\n",
    "df_invalid = df[~df['code'].isin(valid_codes)]\n",
    "print(df_invalid)\n",
    "# Output: C and D rows\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "claims = pd.dataFrame({'claim_id': [1, 2, 3], 'member_id': [101, 102, 103]})\n",
    "icd_ref =pd.dataFrame({\"cpt_code\": ['A', 'B', 'C', 'D'], 'cpt_description': ['desc1', 'desc2', 'desc3', 'desc4']})\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "emp_df = pd.read_parquet(\"/Volumes/workspace/default/emp/emp_parquet_salt/\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "emp_df = pd.read_parquet(\n",
    "    \"/Volumes/workspace/default/emp/emp_parquet_salt/\",\n",
    "    engine='fastparquet'\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "emp_df = pd.read_parquet(\"/Volumes/workspace/default/emp/Badrec/\")\n",
    "emp_df.display()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "emp_delta = pd.read_parquet(\"workspace.default.budget_pivot\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "df_claims = pd.read_parquet('s3://my-bucket/claims.parquet', storage_options={\"key\": \"XXX\", \"secret\": \"YYY\"})\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "claim_df = pd.read_sql(\"SELECT * FROM CALIMS\", engine)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %pip install sqlalchemy\n",
    "# MAGIC\n",
    "# MAGIC from sqlalchemy import create_engine\n",
    "# MAGIC import pandas as pd\n",
    "# MAGIC\n",
    "# MAGIC # Assuming 'engine' is defined somewhere in your code\n",
    "# MAGIC claim_df = pd.read_sql(\"SELECT * FROM CALIMS\",con)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Example: PostgreSQL\n",
    "engine = create_engine(\"postgresql+psycopg2://username:password@host:port/database\")\n",
    "\n",
    "df_claims = pd.read_sql(\"SELECT * FROM claims\", engine)\n",
    "df_icd_ref = pd.read_sql(\"SELECT * FROM icd_codes\", engine)\n",
    "df_providers = pd.read_sql(\"SELECT * FROM providers\", engine)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC **SNOWFLAKE DATABASE**\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "engine = create_engine(\n",
    "    'snowflake://{SUGANTHIB}:{HarishKanish12345}@{oeogihx-rsa96490}/{GOLD}/{CLAIMS}?warehouse={COMPUTE_WH}'.format(\n",
    "        user='SUGANTHIB',\n",
    "        password='',\n",
    "        account='oeogihx-rsa96490',\n",
    "        database='GOLD',\n",
    "        schema='CLAIMS',\n",
    "        warehouse='COMPUTE_WH'\n",
    "    )\n",
    ")\n",
    "#df_claims = pd.read_sql(\"SELECT * FROM CLAIMS\", engine)\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "engine = create_engine(\n",
    "    'snowflake://{user}:{password}@{account}/{database}/{schema}?warehouse={warehouse}'.format(\n",
    "        user='SUGANTHIB',\n",
    "        password=''\n",
    "        account='oeogihx-rsa96490',\n",
    "        database='GOLD',\n",
    "        schema='CLAIMS',\n",
    "        warehouse='COMPUTE_WH'\n",
    "    )\n",
    ")\n",
    "#df_claims = pd.read_sql(\"SELECT * FROM CLAIMS\", engine)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "options = {\n",
    "    \"sfUrl : \": \"oeogihx-rsa96490.snowflakecomputing.com\",\n",
    "    \"sfUser\": \"SUGANTHIB\",\n",
    "    \"sfPassword\": \"\",\n",
    "    \"sfDatabase\": \"GOLD\",\n",
    "    \"sfSchema\": \"CLAIMS\",\n",
    "    \"sfWarehouse\": \"COMPUTE_WH\"\n",
    "}\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# emp_df = pd.read_parquet(\"/Volumes/workspace/default/emp/Badrec/\")\n",
    "# emp_df.display()\n",
    "emp_df = spark.read.format(\"csv\").option(\"inferSchema\",True).option(\"header\", \"true\").csv(\"/Volumes/workspace/default/emp/Badrec/\").write.format(\"snowflake\").options(**options).mode(\"append\").option(\"DBTable\", \"EMP\").save()\n",
    "\n",
    "\n",
    "# COMMAND ----------\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {},
   "notebookName": "NEW DATA VALIDATION",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
