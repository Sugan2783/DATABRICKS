{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55d24de4-cbe0-426c-b441-4b7140f011bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from config_file import INGESTION_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b061dd6-6712-4cbd-8e7e-53326ce87227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog prod;\n",
    "use schema bronze;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc2932a9-0632-46e1-9dc2-1adb7ca5c7a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [],
   "source": [
    "for item in INGESTION_CONFIG:\n",
    "    print(item['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ccaada5-1d05-476d-ae6e-032238d6927a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for item in INGESTION_CONFIG:\n",
    "    df = (\n",
    "        spark.read.format(\"csv\").option(\"header\", True).option(\"inferSchema\", True).load(item['path'])\n",
    "    )\n",
    "   \n",
    "    (\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(item['table'])\n",
    "    )\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02a797c9-9422-4d38-b9d3-298a4b040ea5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "for item in INGESTION_CONFIG:\n",
    "    df = (\n",
    "        spark.read.format(\"csv\").option(\"header\", True).option(\"inferSchema\", True).load(item['path'])\n",
    "    )\n",
    "    # Replace invalid characters in column names\n",
    "    valid_columns = [re.sub(r'[ ,;{}()\\n\\t=]', '_', col) for col in df.columns]\n",
    "    df = df.toDF(*valid_columns)\n",
    "    (\n",
    "        df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(item['table'])\n",
    "    )\n",
    "    display(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7702832074021826,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "INSURANCE_CONFIG_BRONZE_TABLE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
