{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8708ba-8fa5-403e-94ce-99c4a2a5f33d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf9aab5-3575-4fbe-bae4-85ea6978447a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def second_highest_salary(employee: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_emp = employee\n",
    "    df_max = df_emp.groupby['id'].agg({'salary':'max'})\n",
    "    df_max = df_max.sort_values(by = 'id', inplace = True)\n",
    "    df_max2 = df_max.groupby['id'].agg({'salary':'max'})\n",
    "    df_max2 = df_max2.sort_values(by = 'id', inplace = True)\n",
    "    return df_max2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddede581-b99f-4bf9-9d08-d36fcabd41ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Salary': [50000, 60000, 70000, 60000, 80000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop duplicates, sort salaries, and get second highest\n",
    "second_highest_salary = df['Salary'].drop_duplicates().nlargest(2).iloc[-1]\n",
    "\n",
    "# Optionally, get employees with that salary\n",
    "second_highest_earners = df[df['Salary'] == second_highest_salary]\n",
    "\n",
    "print(\"Second highest salary:\", second_highest_salary)\n",
    "print(\"\\nEmployees with second highest salary:\")\n",
    "print(second_highest_earners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2e7aaa7-cee9-44ed-a3e3-ffa6c0723e1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44dcb045-9382-4fd7-9c5c-4cc2a5c37e7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "a =[1,2,3,4,5]\n",
    "a_arr = np.array(a)\n",
    "print(a_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3add5a-5234-42d8-80f4-16f9484eed33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    from pyspark.sql import SparkSession\n",
    "    spark = SparkSession.builder.appName(\"RDD_Example\").getOrCreate()\n",
    "    sc = spark.sparkContext # Get the SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67258b44-dec3-4f97-912f-183c8ddd2722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RDD_Example\").getOrCreate()\n",
    "# Use the spark variable to interact with the SparkSession instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c73851b7-22ee-4335-9749-fadd7028ee18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4, 5]\n",
    "rdd_from_collection = sc.parallelize(data)       "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pandas_leet",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
