{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c027d178-5a29-4ebf-a478-dcc098bfdea5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "create data"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import datetime, datetime, FloatType, StringType, StructField, StructType, IntegerType, LongType, ArrayType, DoubleType\n",
    "from datetime import date, timedelta\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "data = []\n",
    "start_date = date(2024,1,1)\n",
    "\n",
    "\n",
    "for i in range(1,1001):\n",
    "    current_date = start_date + timedelta(days = i)\n",
    "    data.append((str(current_date), f\"product {i % 4}\", i * 5, f\"region_{i % 3}\"))\n",
    "\n",
    "columns = [\"date\", \"product\", \"amount\", \"region\"]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad5e30f-3928-4619-b40a-2a102813c6ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import datetime, datetime, FloatType, StringType, StructField, StructType, IntegerType, LongType, ArrayType, DoubleType\n",
    "from datetime import date, timedelta\n",
    "from pyspark.sql.window import Window\n",
    "import random\n",
    "\n",
    "data = []\n",
    "start_date = date(2024,1,1)\n",
    "\n",
    "\n",
    "for i in range(1,1001):\n",
    "    current_date = start_date + timedelta(days = i)\n",
    "    name = (\"TV\", \"AC\", \"Fridge\", \"Washing Machine\")\n",
    "    data.append((f\"prodid_{i % 4}\", random.choice(name), i * 5500, f\"region_{i % 3}\", str(current_date)))\n",
    "\n",
    "columns = [\"prodid\", \"prodname\", \"amount\", \"region\", \"date\"]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd5be3cb-3c38-4280-9d3a-365181e5311c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
