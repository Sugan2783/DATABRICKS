{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0292857-0f1a-4876-b447-c5d4b65a89d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Volumes/workspace/default/emp/cust_address_json.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a204dc7-d09a-4361-8f2b-432ae5cb99f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_json = spark.read.format(\"csv\").option(\"inferSchema\",True).option(\"header\",True).load('/Volumes/workspace/default/emp/cust_address_json.csv')\n",
    "df_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eb974e4-611e-4a0f-839a-17bd33fcbef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_col = df_json.columns\n",
    "print(df_col)\n",
    "df_sel = df_json.select(df_col[:])\n",
    "display(df_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5816a246-7a8a-4af3-adbb-00ed79f618f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXPLODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c982bd1-5a2a-494b-ad92-28f8474ccd71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sample data\n",
    "data = [(1, \"Jayesh\", \"Tendulkar\", 101, ['SQL','Data Science','PySpark']),\n",
    "        (2, \"Rohit\", \"Sharma\", 102, ['Data Analytics','ML','AI']),\n",
    "        (3, \"Sai\", \"Ramesh\", 101, ['SSMS','Azure','AWS','DEVOPS']),\n",
    "        (4, \"Sreedhar\", \"Arava\", 102, ['Database','Oracle','ADF']),\n",
    "        (5, \"Somesh\", \"yadav\", 101, ['SQL','Data Science','GitHub','PANDAS']),\n",
    "        (6, \"Radhika\", \"Gupta\", 102, ['DEVOPS','AWS','SSMS','Python'])\n",
    "       ]\n",
    "\n",
    "columns = [\"emp_id\", \"first_name\", \"last_name\", \"dept_id\", \"Technology\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "display(df)\n",
    "\n",
    "# display data types\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62f3fc76-38cf-4e65-b387-26a90cd15bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df_exp = df.select(\"emp_id\",\"first_name\",\"last_name\",\"dept_id\",explode(\"Technology\").alias(\"coretech\"))\n",
    "df_exp.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80f5b07-6e2f-4b75-9340-dadf0c347258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(\"Revanth\", [[\"ADF\", \"Spark\", \"ADB\"], [\"ETL\", \"Devops\", None], [\"SQL\", None]]),\n",
    "        (\"Reshma\", [[\"SSMS\", None, \"Salesforce\"], [\"SAP\", \"ERP\", None]]),\n",
    "        (\"Raashi\", [[\"Python\" \"VB\", None], [\"C++\", \"GitHub\", \"Git\"]]),\n",
    "        (\"Krishna\", [[\"SHELL\", \"DRG\"], [\"JAVA\", None]]),\n",
    "        (\"Sudarshan\", None),\n",
    "        (\"Kamal\", [])\n",
    "       ]\n",
    "\n",
    "columns = [\"EmpName\", \"Technology\"]\n",
    "\n",
    "df_nest = spark.createDataFrame(data=data, schema=columns)\n",
    "display(df_nest)\n",
    "df_nest.printSchema()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7be091-eb6d-4483-a107-d8d7d68fbb7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_nexp = df_nest.select(\"EmpName\",explode(\"Technology\").alias(\"coretech\"))\n",
    "df_flat = df_nexp.select(\"EmpName\",explode(\"coretech\").alias(\"parsed_array\"))\n",
    "df_nexp.display() \n",
    "df_flat.display()                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7238d680-d8ee-4348-bfa7-50e48b87d29a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90d44344-3dd2-471d-a454-198c59d34de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Sample data for df1 and df2\n",
    "data1 = [(1, \"Alice\", \"123456\"), (2, \"Bob\", \"789012\")]\n",
    "data2 = [(1, \"12345\", \"123 Main St\", \"CityA\"), (2, \"67890\", \"456 Elm St\", \"CityB\")]\n",
    "\n",
    "columns1 = [\"id\", \"name\", \"mobno\"]\n",
    "columns2 = [\"id\", \"pincode\", \"address\", \"city\"]\n",
    "\n",
    "df1 = spark.createDataFrame(data1, columns1)\n",
    "display(df1)\n",
    "\n",
    "df2 = spark.createDataFrame(data2, columns2)\n",
    "display(df2)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "186fcf87-c4de-4870-abc2-435f76475818",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_join = df1.join(df2, df1.id == df2.id, \"inner\")\n",
    "display(df_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50981bc1-7865-4beb-b972-e298e469af6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_jsel = df_json.select(df1.id,\"name\",\"mobno\",\"pincode\",\"address\",\"city\")\n",
    "df_jsel.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39f5333a-8196-4170-9f3c-d28e80e96ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_jsel = df1.withColumnRenamed(\"id\",\"df1_id\").select(\"df1_id\",\"name\",\"mobno\",\"pincode\",\"address\",\"city\")\n",
    "df_jsel.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69740ab2-bb9a-423b-bded-37c854ba4fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Q1) How to find null rows in columns using pyspark?\n",
    " \n",
    " Q2) How do you clean below data using databricks. Handling blank and null?\n",
    "\n",
    "         name         email        phoneNo   country\n",
    "         xyz          blank         1234      null\n",
    "         null    abs@gmail.com      blank     blank\n",
    "         abc          null          null      india\n",
    "         def     xyz@gmail.com      5678      sweden\n",
    "         None         None          None      None\n",
    "\n",
    " # Sample data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d660da0a-4aff-4fc1-be16-4616591dde76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "     (\"xyz\", \"blank\", \"1234\", None),\n",
    "     (None, \"abs@gmail.com\", \"blank\", \"blank\"),\n",
    "     (\"abc\", None, None, \"india\"),\n",
    "     (\"def\", \"xyz@gmail.com\", \"5678\", \"sweden\"),\n",
    "     (None, None, None, None)]\n",
    "\n",
    "schema = [\"name\",\"email\",\"phno\",\"country\"]\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8e55e1b-7565-4e17-8157-7201c1fcd397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_null = df.filter(df.name.isNull() | df.email.isNull() | df.phno.isNull() | df.country.isNull())\n",
    "display(df_null)\n",
    "df_clean = df.filter(df.name.isNotNull() & df.email.isNotNull() & df.phno.isNotNull() & df.country.isNotNull())\n",
    "display(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aa2f80f-1c70-4f73-a7a8-f45670587372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fill = df.fillna({\"name\" : \"alpha\", \"email\" : \"abc@email.com\", \"phno\": \"67999\", \"country\": \"USA\"})\n",
    "df_fill.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566f6d27-9fe4-4eb2-8e8f-decea0a3f37e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_all_null = df.filter(df_null.name.isNull() & df_null.email.isNull() & df_null.phno.isNull() & df_null.country.isNull())\n",
    "df_all_null.drop.display()\n",
    "\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e83ba3d-0a15-4bf9-90be-86f1b54c1fd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cole = df_null.dropna(how ='any', subset = ([\"name\",\"email\",\"phno\",\"country\"]))\n",
    "df_cole.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "645bbf93-d94a-4601-a1e6-e6bb8b5e11d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# i) How to read above json using pyspark?\n",
    "#  ii) How to get the `email` from `contacts` from above json using same code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aa9f951-d03b-49d6-a2b3-10c592f80fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample JSON data\n",
    "json_data = '''\n",
    "{\n",
    "  \"id\": 1,\n",
    "  \"name\": \"John\",\n",
    "  \"details\": {\n",
    "    \"age\": 25,\n",
    "    \"gender\": \"Male\",\n",
    "    \"address\": {\n",
    "      \"street\": \"123 Main St\",\n",
    "      \"city\": \"Anytown\",\n",
    "      \"state\": \"CA\",\n",
    "      \"zip\": \"12345\"\n",
    "    },\n",
    "    \"contacts\": {\n",
    "      \"email\": \"john@example.com\",\n",
    "      \"phone\": \"+1-555-123-4567\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "dbutils.fs.put('/Volumes/workspace/default/emp/json_data.json', json_data, True)\n",
    "#df = spark.read.json('/Volumes/workspace/default/emp/json_data.json')\n",
    "\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd6dfab-76a2-49fe-9d39-322ac9ec433e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_json = spark.read.format('json')\\\n",
    "                    .option('header', True)\\\n",
    "                    .option('inferSchema', True)\\\n",
    "                    .option('multiLine', True)\\\n",
    "                    .load(\"/Volumes/workspace/default/emp/json_data.json\")\n",
    "display(df_json)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ab1247-1cbc-443b-9b69-15439262ed24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract the email from contacts\n",
    "email_df = df_json.select(\"id\",\"name\",col(\"details.age\").alias(\"age\"),col(\"details.gender\").alias(\"gender\"),col(\"details.address.city\").alias(\"city\"),col(\"details.address.state\").alias(\"state\"),col(\"details.address.zip\").alias(\"zip\"),col(\"details.contacts.email\").alias(\"email\"),col(\"details.contacts.phone\").alias(\"phone\"))\n",
    "\n",
    "# Display the email DataFrame\n",
    "display(email_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83453b2-bf44-4e99-94ef-b6f14c96741b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "df_jsonp = df_json.select(\n",
    "    col(\"details.address.city\").alias(\"city\"),\n",
    "    col(\"details.address.state\").alias(\"state\"),\n",
    "    col(\"details.address.street\").alias(\"street\"),\n",
    "    col(\"details.address.zip\").alias(\"zip\")\n",
    ")\n",
    "display(df_jsonp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6322b628-f615-4d5c-8182-80c90e46ecf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, [\"a\", \"b\", \"c\"], \"d\")\n",
    "]\n",
    "\n",
    "# Define schema\n",
    "columns = [\"item_id\", \"c1\", \"c2\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df_Q4 = spark.createDataFrame(data, columns)\n",
    "display(df_Q4)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f9ea6a-bb4c-411f-a71f-3a72eab16399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_p = df_Q4.withColumn(\"c1_new\", df_Q4.c1[0]).alias(\"c1\").withColumn(\"c2_new\", df_Q4.c1[1]).alias(\"c2\").withColumn(\"c3_new\", df_Q4.c1[2]).alias(\"c3\")\n",
    "display(df_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1439ffda-ae7f-4a44-890f-207d6442d9f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = [\"Name\", \"SkillSet\"]\n",
    "    \n",
    "data = ([\"ABC\", ['.Net', 'Git', 'C#']],\n",
    "        [\"XYZ\", ['Wordpress', 'PHP']],\n",
    "        [\"IJK\", ['Python', 'MongoDB', 'Git']],\n",
    "        [\"DEF\", ['SSIS', 'SSAS', 'Power BI', 'SQL Server', 'Data Warehouse']],\n",
    "        [\"PQR\", ['Azure']])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show(truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82c39dad-b173-49e9-a03a-6ec18304399e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df = df.withColumn(f\"skill_{i}\", df.SkillSet.getItem(i))\n",
    "    \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02d07b83-9a96-4afb-ad80-5ffbea7055ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = [\"Name\", \"SkillSet\"]\n",
    "    \n",
    "data = ([\"ABC\", ['.Net', 'Git', 'C#']],\n",
    "        [\"XYZ\", ['Wordpress', 'PHP']],\n",
    "        [\"IJK\", ['Python', 'MongoDB', 'Git']],\n",
    "        [\"DEF\", ['SSIS', 'SSAS', 'Power BI', 'SQL Server', 'Data Warehouse']],\n",
    "        [\"PQR\", ['Azure']])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show(truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d182f2-bc17-438f-acc2-423600f68037",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "d21 = df.withColumn(\"Skill1\", df['SkillSet'][0]) \\\n",
    "        .withColumn(\"Skill2\", df['SkillSet'][1]) \\\n",
    "        .withColumn(\"Skill3\", df['SkillSet'][2]) \\\n",
    "        .withColumn(\"Skill4\", df['SkillSet'][3]) \\\n",
    "        .withColumn(\"Skill5\", df['SkillSet'][4])\n",
    "d21.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c954bc0-2532-4fae-8f0d-72ed5b3c64cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dfsize = df.select(\"Name\", \"SkillSet\", size(\"SkillSet\").alias(\"NoOfArrayElements\"))\n",
    "dfsize.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3a9aaaa-d89b-487f-8822-0e32d956717d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_val = dfsize.select(max(\"NoOfArrayElements\")).collect()[0][0]\n",
    "print(max_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25bbf9eb-c3da-428d-9a70-e17b7e8a77b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def maxarray(df, maxval):\n",
    "    for i in range(maxval):\n",
    "        df = df.withColumn(f\"skill_{i}\", df['SkillSet'][i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8fec0e2-96c1-47e3-b0fc-9a5059061a25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_out = maxarray(df, max_val)\n",
    "df.show(truncate=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba1c587-f992-47ca-a9df-1e0b0b40ad5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.select('Name', 'SkillSet', df.SkillSet[0].alias('Skill1'),\\\n",
    "                              df.SkillSet[1].alias('Skill2'),\\\n",
    "                              df.SkillSet[2].alias('Skill3'),\\\n",
    "                              df.SkillSet[3].alias('Skill4'),\\\n",
    "                              df.SkillSet[4].alias('Skill5')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5a6edd-91d8-41fe-8bbf-fb3058105004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_split = spark.read.format(\"csv\").option(\"header\",True).option(\"inferSchema\",True).load(\"/Volumes/workspace/default/emp/SPLIT_PY.csv\")\n",
    "\n",
    "df_split.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1065dd62-27c4-4801-b9a6-1ca56f5f69a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_new = df_split.withColumn(\"new_column\", split(\"column2\",'\\|')[0]).withColumn(\"new_col2\",split(\"column2\",'\\|')[1])\n",
    "df_new.display()\n",
    "df_nnew = df_new.withColumn(\"new_column1\", split(\"new_column\", '-')[0])\n",
    "df_nnew.display()\n",
    "#df_new = df_split.withColumn(\"new_column\", split(\"column2\",'\\|')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0eaf4f5-7c10-49e8-a736-3300effd0eef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize two lists\n",
    "subjects1 = [\"Java\",\"Python\",\"PHP\",\"SQL\"]\n",
    "subjects2 = ['C#','CPP','C','plsql']\n",
    "\n",
    "final = list(zip(subjects1,subjects2))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b594a49-767d-43f0-a19c-e5025a47f4f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import locate\n",
    "\n",
    "# Sample data\n",
    "data = [(\"Azure data engineer (ADE)\", \"suman@gmail.com\"),\n",
    "        (\"AWS data engineer (AWS)\", \"kiranrathod@gmail.com\"),\n",
    "        (\"data warehouse\", \"rameshwaran@gmail.com\"),\n",
    "        (\"GCP engineer\", \"krishnamurthy@gmail.com\"),\n",
    "        (\"PySpark engineer\", \"vishweswarrao@gmail.com\")]\n",
    "\n",
    "columns = [\"text\", \"mail\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "742f7ef3-feb3-473d-9571-c8de2b13daf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_exp = df.withColumn(\"position\", locate(\"data\", df.text))\n",
    "df_exp.show()\n",
    "df_exp.filter(df_exp.position > 0).show()\n",
    "\n",
    "df_email = df.withColumn(\"email_pos\",locate(\"@\", df.mail)).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "246505dc-7658-4cfe-8514-80edd6dcc419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_em = df_email.withColumn(\n",
    "    \"new_mail\",\n",
    "    substring(df_email.mail, df_email.email_pos + 1, length(df_email.mail) - df_email.email_pos)\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b28fb52d-bf86-488f-b9ac-9924311b2caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec5a27e4-024f-47ea-905b-dad2efcec22c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df_em = df_email.select(\"text\", \"mail\", \"email_pos\")\n",
    "df_ex = withColumn(\"newcval\",expr('substring(\"mail\",1,locate(\"@\",mail)) '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72af1040-6a6b-4ff1-be43-567a1cd67f8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_ex = df_email.withColumn(\n",
    "    \"newcval\",\n",
    "    expr('substring(\"mail\", 1, instr(\"mail\", \"@\"))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef60dfba-2105-4ae7-a8fe-44adf82ec98f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_em = df_email.withColumn(\"new_mail\", substring(df.mail, df.email_pos+1, length(df.mail)-df.email_pos)).display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5749785767324940,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SELECT 3 columns_Suresh",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
