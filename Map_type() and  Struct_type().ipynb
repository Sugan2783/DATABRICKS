{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9380a1a-5b71-4273-a445-3ea74a4ca4d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**MAp_TYPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86547cdd-a9e7-42bc-8ee9-1befd34354b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, FloatType,MapType\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Sample DataFrame with a StringType column containing JSON strings\n",
    "data = [(\"Naresh\", \"Bangalore\", {\"Domain\": \"Gas\", \"Branch\": \"IT\", \"Designation\": \"DE\", \"Company\": \"TCS\", \"Mode\": \"Transport\"}), \n",
    "        (\"Harish\", \"Chennai\", {\"Domain\": \"DS\", \"Branch\": \"CSC\", \"Designation\": \"DE\", \"Company\": \"Sony\"}),\n",
    "        (\"Prem\", \"Hyderabad\", {\"Domain\": \"Trade\", \"Branch\": \"EEE\", \"Designation\": \"DE\"}), \n",
    "        (\"Prabhav\", \"kochin\", {\"Domain\": \"Sales\", \"Branch\": \"AI\"}),\n",
    "        (\"Hari\", \"Nasik\", {\"Domain\": \"TELE\"}), \n",
    "        (\"Druv\", \"Delhi\", None),\n",
    "]\n",
    "\n",
    "schema = StructType([StructField(\"name\", StringType(),True),\n",
    "                     StructField(\"city\", StringType(), True),\n",
    "                     StructField(\"Properties\", MapType(StringType(), StringType()),True)\n",
    "                    ])\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.printSchema()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "628af024-09a3-404c-8656-b2b1d249da8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, FloatType, MapType\n",
    "\n",
    "# Sample DataFrame with a StringType column containing JSON strings\n",
    "data = [(\"Naresh\", \"Bangalore\", {\"Domain\": \"Gas\", \"Branch\": \"IT\", \"Designation\": \"DE\", \"Company\": \"TCS\", \"Mode\": \"Transport\"}), \n",
    "        (\"Harish\", \"Chennai\", {\"Domain\": \"DS\", \"Branch\": \"CSC\", \"Designation\": \"DE\", \"Company\": \"Sony\"}),\n",
    "        (\"Prem\", \"Hyderabad\", {\"Domain\": \"Trade\", \"Branch\": \"EEE\", \"Designation\": \"DE\"}), \n",
    "        (\"Prabhav\", \"kochin\", {\"Domain\": \"Sales\", \"Branch\": \"AI\"}),\n",
    "        (\"Hari\", \"Nasik\", {\"Domain\": \"TELE\"}), \n",
    "        (\"Druv\", \"Delhi\", None),\n",
    "]\n",
    "\n",
    "schema = StructType([StructField(\"name\", StringType(), True),\n",
    "                     StructField(\"city\", StringType(), True),\n",
    "                     StructField(\"Properties\", MapType(StringType(), StringType()), True)\n",
    "                    ])\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0df967f-d042-4eaa-a801-8e25b85e225c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import MapType, StringType, IntegerType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# A list of rows, each with a map\n",
    "data = [\n",
    "    Row(name=\"Albert\", properties={\"age\": 25, \"height\": 12, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"blue\"}),\n",
    "    Row(name=\"Bobby\", properties={\"age\": 30, \"height\": 15, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": None}),\n",
    "    Row(name=\"Anand\", properties={\"age\": 28, \"height\": 18, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"black\"}),\n",
    "    Row(name=\"Chandra\", properties={\"age\": None, \"height\": 22, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"white\"}),\n",
    "    Row(name=\"Seetha\", properties={\"age\": 45, \"height\": 32, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"yellow\"}),\n",
    "    Row(name=\"Varun\", properties={\"age\": 32, \"height\": 10, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": None}),\n",
    "    Row(name=\"Bobby\", properties={\"age\": None, \"height\": 19, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"blue\"}),\n",
    "    Row(name=\"Bobby\", properties={\"age\": 30, \"height\": 8, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"brown\"}),\n",
    "    Row(name=\"Anand\", properties={\"age\": None, \"height\": 16, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": None}),\n",
    "    Row(name=\"Chandra\", properties={\"age\": 35, \"height\": 13, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"white\"}),\n",
    "    Row(name=\"Seetha\", properties={\"age\": 45, \"height\": 27, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": \"yellow\"}),\n",
    "    Row(name=\"Anand\", properties={\"age\": 32, \"height\": 29, \"Gender\": \"Male\", \"Country\": \"India\", \"eyeColor\": None})\n",
    "]\n",
    "\n",
    "# Define the schema\n",
    "schema = [\"name\", \"properties\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "display(df)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ec9eef-bfa6-4a91-8de0-8287af943a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_col = df.select(\"name\", col(\"properties\")[\"Country\"].alias(\"country\"),\n",
    "                   col(\"properties\")[\"height\"].alias(\"height\"),\n",
    "                   col(\"properties\")[\"age\"].alias(\"age\"),\n",
    "                   col(\"properties\")[\"Gender\"].alias(\"gender\"),\n",
    "                   col(\"properties\")[\"eyeColor\"].alias(\"eyecolor\")\n",
    "                   )\n",
    "\n",
    "df_col.where(col(\"age\").isNull()).select(\"*\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Map_type() and  Struct_type()",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
