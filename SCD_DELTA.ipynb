{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d83cc52-d828-402b-9163-94b802a02608",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SCD1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20869ea9-ea6f-4442-bb03-71a382270069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [(1,\"Alice\",\"NewYork\", \"2010-01-01\"),\n",
    "        (2,\"Bob\",\"Chicago\", \"2010-01-02\")]\n",
    "      \n",
    "cols =[\"customer_id\", \"name\", \"city\", \"date\"]\n",
    "\n",
    "df_initial = spark.createDataFrame(data, cols)\n",
    "\n",
    "df_initial.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/default/emp/customer_dim\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1f048b7-188b-4a8b-b8ec-a24706de55e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from customer_dim;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a109321-0377-458f-be0b-c1943fa93f7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "update =[(1,\"Alice\",\"London\", \"2011-01-01\")]\n",
    "\n",
    "df_updates = spark.createDataFrame(update, cols)\n",
    "\n",
    "#df_updates.write.format(\"delta\").mode(\"append\").saveAsTable(\"customer_dim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eac46a3f-b8f9-4391-bbf9-258302f02f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "dim_path = \"/Volumes/workspace/default/emp/customer_dim\"\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, dim_path)\n",
    "\n",
    "deltaTable.alias(\"tgt\").merge(\n",
    "    df_updates.alias(\"src\"),\n",
    "    \"tgt.customer_id = src.customer_id\") \\\n",
    "  .whenMatchedUpdateAll() \\\n",
    "  .whenNotMatchedInsertAll() \\\n",
    "  .execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8ef4d4-4b3f-458a-9dc5-40bb63f56151",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deltaTable.alias(\"tgt\").merge(\n",
    "    df_updates.alias(\"src\"),\n",
    "    \"tgt.customer_id = src.customer_id\") \\\n",
    "  .whenMatchedUpdate(set={\n",
    "      \"name\": \"src.name\",\n",
    "      \"city\": \"src.city\",\n",
    "      \"date\": \"src.date\"})\\\n",
    "  .whenNotMatchedInsert(values = {\n",
    "      \"customer_id\": \"src.customer_id\",\n",
    "      \"name\": \"src.name\",\n",
    "      \"city\": \"src.city\",\n",
    "      \"date\": \"src.date\"}) \\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69667ab4-6040-4440-800a-58e382677f27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\").load(dim_path).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40752b17-6b39-41d8-b9e6-0bebeca2f8cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SCD 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63bae85d-8183-4152-97d0-7515195da0e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "deltaTable.update(\n",
    "  condition = \"True\",\n",
    "  set ={\n",
    "    \"start_date\" : \"2020-01-01\",\n",
    "    \"end_date\" : lit(None),\n",
    "    \"Iscurrent\" : lit(True)}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe9c8df2-4326-4fa5-a66a-53e7875019b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data1 = [(1,\"Alice\",\"NewYork\", \"2010-01-01\",current_date(),lit(None),True),\n",
    "        (2,\"Bob\",\"Chicago\", \"2010-01-02\",current_date(),lit(None),True)]\n",
    "\n",
    "\n",
    "      \n",
    "cols1 =[\"customer_id\", \"name\", \"city\", \"date\",\"start_date\",\"end_date\", \"Iscurrent\"]\n",
    "\n",
    "df_sc2 = spark.createDataFrame(data1, cols1)\n",
    "\n",
    "df_sc2.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/default/emp/customer_dim_scd2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d533360c-cbd6-476a-b857-aca6964f35ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, BooleanType\n",
    "from pyspark.sql.functions import current_date, lit\n",
    "\n",
    "data1 = [(1, \"Alice\", \"NewYork\", \"2010-01-01\", \"2010-01-01\", None, 'Y'),\n",
    "         (2, \"Bob\", \"Chicago\", \"2010-01-02\", \"2010-01-02\", None, 'Y')]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"start_date\", StringType(), True),\n",
    "    StructField(\"end_date\", StringType(), True),\n",
    "    StructField(\"Iscurrent\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_sc2 = spark.createDataFrame(data1, schema)\n",
    "\n",
    "df_sc2.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/default/emp/customer_dim_scd2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0c69e62-f87f-436e-b562-f98532fb784c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, \"/Volumes/workspace/default/emp/customer_dim_scd2\")\n",
    "\n",
    "deltaTable.alias(\"tgt\").merge(\n",
    "    df_sc2.alias(\"src\"),\n",
    "    \"tgt.customer_id = src.customer_id AND Iscurrent = 'Y'\")\\\n",
    "  .whenMatchedUpdate(condition = \"src.city > tgt.city\",\n",
    "                     set = {\n",
    "                         \"end_date\": current_date(),\n",
    "                         \"Iscurrent\": lit(False)\n",
    "                     })\\\n",
    "  .whenNotMatchedInsert(values = {\n",
    "      \"customer_id\": \"src.customer_id\",\n",
    "      \"name\": \"src.name\",\n",
    "      \"city\": \"src.city\",\n",
    "      \"date\": \"src.date\",\n",
    "      \"start_date\": lit(\"2021-05-01\"),\n",
    "      \"end_date\": lit(None),\n",
    "      \"Iscurrent\": lit('N')\n",
    "  }).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c99a01-0489-46eb-9cb2-1149527ac262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, lit\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "deltable = DeltaTable.forPath(spark, \"/Volumes/workspace/default/emp/customer_dim_scd2\")\n",
    "\n",
    "deltable.alias(\"tgt\").merge(\n",
    "    df_sc2.alias(\"src\"),\n",
    "    \"tgt.customer_id = src.customer_id AND src.Iscurrent = 'Y'\")\\\n",
    "  .whenMatchedUpdate(condition = \"src.city > tgt.city\",\n",
    "                     set = {\n",
    "                         \"end_date\": current_date(),\n",
    "                         \"Iscurrent\": lit(False)\n",
    "                     })\\\n",
    "  .whenNotMatchedInsert(values = {\n",
    "      \"customer_id\": \"src.customer_id\",\n",
    "      \"name\": \"src.name\",\n",
    "      \"city\": \"src.city\",\n",
    "      \"date\": \"src.date\",\n",
    "      \"start_date\": lit(\"2021-05-01\"),\n",
    "      \"end_date\": lit(None),\n",
    "      \"Iscurrent\": lit('N')\n",
    "  }).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e145544c-4175-429a-bf3e-e6d969bf41f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\").load(\"/Volumes/workspace/default/emp/customer_dim_scd2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b548228-ff5b-4e04-8cb5-8d89b5d8ce58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "199cf28d-5db6-45c7-8b86-05d4fbef9a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "update1 =[(4,\"John\",\"PEnn\", \"2011-01-01\",None,None,'Y')]\n",
    "\n",
    "schema1 = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"start_date\", StringType(), True),\n",
    "    StructField(\"end_date\", StringType(), True),\n",
    "    StructField(\"Iscurrent\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_upd_scd2 = spark.createDataFrame(update1, schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19e92337-976a-4f4b-8b47-d604763d9cec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, lit\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, \"/Volumes/workspace/default/emp/customer_dim_scd2\")\n",
    "\n",
    "deltaTable.alias(\"tgt\").merge(\n",
    "    df_upd_scd2.alias(\"src\"),\n",
    "    \"tgt.customer_id = src.customer_id AND src.Iscurrent = 'Y'\")\\\n",
    "  .whenMatchedUpdate(condition = \"src.city <> tgt.city\",\n",
    "                     set = {\n",
    "                         \"end_date\": current_date(),\n",
    "                         \"Iscurrent\": lit('N')\n",
    "                     })\\\n",
    "  .whenNotMatchedInsert(values = {\n",
    "      \"customer_id\": \"src.customer_id\",\n",
    "      \"name\": \"src.name\",\n",
    "      \"city\": \"src.city\",\n",
    "      \"date\": \"src.date\",\n",
    "      \"start_date\": lit(\"2021-05-01\"),\n",
    "      \"end_date\": lit(None),\n",
    "      \"Iscurrent\": lit('Y')\n",
    "  }).execute()0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caa052dc-0cde-4aa3-a35a-cd92293a71db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\").load(\"/Volumes/workspace/default/emp/customer_dim_scd2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c5c4525-5da4-42e4-8229-3f139e8b5181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72f30f07-9ba4-4d52-88a5-fa9b94b44279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tgt_claim = DeltaTable.forPath(spark, '/Volumes/dev/bronze/transactions/cptcodes.parquet/')\n",
    "\n",
    "tgt_cptcodes.alias(\"tgt\").merge(\n",
    "    \n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5078835239715064,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SCD_DELTA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
