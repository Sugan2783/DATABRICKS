{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dccee59-f1bb-4e5d-82e9-cfd8b7c29c05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "def text_file_read(file_path,sep):\n",
    "    df=spark.read.text(file_path)\n",
    "    header=df.first()[0].split(sep)\n",
    "    rm_header=df.filter(col(\"value\")!=sep.join(header))\n",
    "    df_split=rm_header.select(split(col(\"value\"),sep).alias(\"parts\"))\n",
    "    df_final=df_split.selectExpr(*[f\"parts[{i}] as {header[i]}\" for i in range(len(header))])\n",
    "    return df_final\n",
    "\n",
    "file_path=\"/Volumes/bigdata/bdata/customer/customer_feedback.txt\"\n",
    "sep=\"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75afe1db-72c1-4b01-9cfa-7c8471e16acf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "what is structtype?\n",
    " It is root type for definjjing schemain pyspark\n",
    " schema = collection of columns\n",
    " column = name and type\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12ce6443-79e3-4b19-9f76-7d497dcb6a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd979e89-d69c-421a-849b-954c9245ef17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "data = [(1,(\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],(1000.0,100000.0)),\n",
    "        (2,(\"Michael\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],(2000.0,200000.0)),\n",
    "        (3,(\"Robert\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],(3000.0,300000.0)),\n",
    "        (4,(\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],(4000.0,40000.0))]\n",
    "                                                                          \n",
    "schema = StructType([ \n",
    "    StructField(\"id\",IntegerType(),True),\n",
    "    StructField(\"name\",StructType([ \n",
    "        StructField(\"firstname\",StringType(),True),\n",
    "        StructField(\"middlename\",StringType(),True),\n",
    "        StructField(\"lastname\",StringType(),True)                     \n",
    "    ]),True),\n",
    "    StructField(\"languages\",ArrayType(StringType()),True),\n",
    "    StructField(\"skilled\", ArrayType(StringType()), True),\n",
    "    StructField(\"salaryinfo\", StructType([\n",
    "        StructField(\"Bonus\", IntegerType(), True),\n",
    "        StructField(\"Salary\", DoubleType(), True)\n",
    "    ]), True)])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.display()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f5a78ab-989b-447b-b26e-d8b5b3466605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_select = df.selectExpr(\"id\", explode(\"name\"), col(\"languages\").substr(1,1), col(\"skilled\")[0], col(\"salaryinfo\")[0][1]).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f8496c4-53be-4fbd-82f7-e40bf8454c14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_select = df.select(\n",
    "    col(\"id\"),\n",
    "    col(\"name.firstname\"),\n",
    "    col(\"name.middlename\"),\n",
    "    col(\"name.lastname\"),\n",
    "    col(\"languages\").substr(1, 1),\n",
    "    col(\"skilled\").getItem(0),\n",
    "    col(\"salaryinfo\").getItem(0).getItem(1)\n",
    ")\n",
    "display(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f33623c-1df9-4b93-a342-867ade6d6037",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, FloatType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"OBJECT_ID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"department\", StringType(), True),\n",
    "    StructField(\"Customer_ID\", IntegerType(), True),\n",
    "    StructField(\"Change_Date\", StringType(), True),\n",
    "    StructField(\"Load_Date\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"start_date_source\", StringType(), True),\n",
    "    StructField(\"start_date_bronze\", StringType(), True)\n",
    "])\n",
    "\n",
    "data = [(583069, \"Harish\", None, 13681832, None, '2025-06-02', None, 'E-Mail', 1724256609000, None),\n",
    "        (510102, \"\", \"HR\", 40685884, '2025-04-02T04:15:05Z', '2025-06-02', 'Finished', 'Internet', 1724256609000, None),\n",
    "        (506654, \"Basha\", \"\", None, '2025-04-02T04:15:05Z', '2025-06-02', 'Not Relevant', 'Social Media', 1724256609000, None),\n",
    "        (583195, None, \"Finance\", 12619703, None, '2025-06-02', 'Started', 'Messaging', 1724256609000, None),\n",
    "        (470450, \"Venky\", \"IT\", 8541938, '2025-04-02T07:59:14Z', '2025-06-02', 'Not Relevant', 'IoT', 1724256609000, None),\n",
    "        (558253, \"\", None, 2269299, None, '2025-06-02', 'Open', None, 1724256609000, None),\n",
    "        (None, \"Krishna\", \"Sales\", None, '2025-04-02T06:12:18Z', '2025-06-02', None, 'Manual data entry', 1724256609000, None),\n",
    "        (583181, \"Kiran\", \"Marketing\", 39714449, None, '2025-06-02', 'Finished', 'Other', 1724256609000, None),\n",
    "        (583119, \"Hitesh\", None, 10183510, '2025-04-02T04:15:13Z', None, 'Open', 'Telephony', 1724256609000, None),\n",
    "        (577519, \"\", \"Accounts\", None, '2025-04-02T08:27:50Z', '2025-06-02', 'Not Relevant', None, 1724256609000, None),\n",
    "        (583151, \"Sushma\", \"Accounts\", 40442877, None, '2025-06-02', 'Open', 'Fax', 1724256609000, None),\n",
    "        (583167, None, \"Admin\", 16474490, '2025-04-02T09:07:27Z', None, 'Not Relevant', 'Feedback', 1724256609000, None),\n",
    "        (583162, \"Buvan\", \"IT\", 7447339, '2025-04-02T16:46:07Z', None, 'Finished', 'WorkZone', 1724256609000, None),\n",
    "        (575216, \"Mohan\", \"Admin\", 17258071, '2025-04-02T01:51:03Z', '2025-06-02', 'Open', 'IOT', 1724256609000, None),\n",
    "        (None, None, None, None, None, None, None, None, None, None),\n",
    "        (583173, \"Lohith\", \"Finance\", 15113750, None, '2025-06-02', 'Finished', None, 1724256609000, None),\n",
    "        (583099, \"Loba\", \"Testing\", 40505376, '2025-04-02T19:54:50Z', None, 'Started', None, 1724256609000, None)\n",
    "       ]\n",
    "\n",
    "df_dev = spark.createDataFrame(data, schema)\n",
    "df_dev.withColumn(\"Customer_ID\", col(\"Customer_ID\").cast(StringType()))\n",
    "display(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c93f26d7-ecd0-40f4-be99-6c3a5b06c30c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sel_col(df, column_name):\n",
    "    return df.filter(col(column_name) == 'Accounts')\n",
    "\n",
    "display(sel_col(df_dev, \"department\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c2ca5c3-8ef5-441d-ac0c-00668ee62039",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sel_col(df, column_name):\n",
    "    return df.filter(col(column_name) == 'HR')\n",
    "\n",
    "display(\n",
    "    sel_col(df_dev, \"department\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99a0a664-570b-4969-9440-64d4f9780e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import try_to_date\n",
    "\n",
    "def ch_date(df, column_name):\n",
    "    new_df = df.withColumn(\"Ch_date\", try_to_date(column_name, 'yyyy-MM-dd'))\n",
    "    return new_df\n",
    "\n",
    "display(ch_date(df_dev, \"Change_Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5ff84c3-b033-4515-ba58-c86427c4c307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "def ch_date(\n",
    "    df,\n",
    "    column_name\n",
    "):\n",
    "    new_df = df.withColumn(\n",
    "        \"Ch_date\",\n",
    "        to_date(column_name, \"yyyy-MM-dd'T'HH:mm:ss'Z'\")\n",
    "    )\n",
    "    return new_df\n",
    "\n",
    "display(\n",
    "    ch_date(df_dev, \"Change_Date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "565f7a8c-b6b6-4d39-aad0-93a7c8881522",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1759721080095}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, year, col, month, date_format, udf\n",
    "\n",
    "def ch_date(\n",
    "    df,\n",
    "    column_name\n",
    "):\n",
    "    new_df = df.withColumn(\n",
    "        \"Ch_date\",\n",
    "        to_date(col(column_name), \"yyyy-MM-dd'T'HH:mm:ss'Z'\")\n",
    "    ).withColumn(\n",
    "        \"year\",\n",
    "        year(col(column_name))\n",
    "    ).withColumn(\"month\", date_format(col(column_name), 'EEEE')\n",
    "    ).withColumn(\"Day\", date_format(col(column_name), 'LLLL'))\n",
    "    return new_df\n",
    "\n",
    "display(\n",
    "    ch_date(df_dev, \"Change_Date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f18f972-690d-418b-9510-4eecf55db975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, year, col, month, date_format, udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "changedate = udf(\"ch_date\", DateType())\n",
    "\n",
    "spark.udf.register(\"changedate\", changedate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e64f6b87-541f-4220-885c-0aca30a4e79d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_new = df_dev.select(changedate('Change_Date'))\n",
    "df_new.display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "STRUCTTYPE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
