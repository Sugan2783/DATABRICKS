{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dccee59-f1bb-4e5d-82e9-cfd8b7c29c05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "def text_file_read(file_path,sep):\n",
    "    df=spark.read.text(file_path)\n",
    "    header=df.first()[0].split(sep)\n",
    "    rm_header=df.filter(col(\"value\")!=sep.join(header))\n",
    "    df_split=rm_header.select(split(col(\"value\"),sep).alias(\"parts\"))\n",
    "    df_final=df_split.selectExpr(*[f\"parts[{i}] as {header[i]}\" for i in range(len(header))])\n",
    "    return df_final\n",
    "\n",
    "file_path=\"/Volumes/bigdata/bdata/customer/customer_feedback.txt\"\n",
    "sep=\"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75afe1db-72c1-4b01-9cfa-7c8471e16acf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "what is structtype?\n",
    " It is root type for definjjing schemain pyspark\n",
    " schema = collection of columns\n",
    " column = name and type\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12ce6443-79e3-4b19-9f76-7d497dcb6a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd979e89-d69c-421a-849b-954c9245ef17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "data = [(1,(\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"],(1000.0,100000.0)),\n",
    "        (2,(\"Michael\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"],(2000.0,200000.0)),\n",
    "        (3,(\"Robert\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],(3000.0,300000.0)),\n",
    "        (4,(\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"],(4000.0,40000.0))]\n",
    "                                                                          \n",
    "schema = StructType([ \n",
    "    StructField(\"id\",IntegerType(),True),\n",
    "    StructField(\"name\",StructType([ \n",
    "        StructField(\"firstname\",StringType(),True),\n",
    "        StructField(\"middlename\",StringType(),True),\n",
    "        StructField(\"lastname\",StringType(),True)                     \n",
    "    ]),True),\n",
    "    StructField(\"languages\",ArrayType(StringType()),True),\n",
    "    StructField(\"skilled\", ArrayType(StringType()), True),\n",
    "    StructField(\"salaryinfo\", StructType([\n",
    "        StructField(\"Bonus\", IntegerType(), True),\n",
    "        StructField(\"Salary\", DoubleType(), True)\n",
    "    ]), True)])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.display()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f5a78ab-989b-447b-b26e-d8b5b3466605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_select = df.selectExpr(\"id\", explode(\"name\"), col(\"languages\").substr(1,1), col(\"skilled\")[0], col(\"salaryinfo\")[0][1]).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f8496c4-53be-4fbd-82f7-e40bf8454c14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_select = df.select(\n",
    "    col(\"id\"),\n",
    "    col(\"name.firstname\"),\n",
    "    col(\"name.middlename\"),\n",
    "    col(\"name.lastname\"),\n",
    "    col(\"languages\").substr(1, 1),\n",
    "    col(\"skilled\").getItem(0),\n",
    "    col(\"salaryinfo\").getItem(0).getItem(1)\n",
    ")\n",
    "display(df_select)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "STRUCTTYPE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
